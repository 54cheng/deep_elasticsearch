# 1、【聚合分析】一个订单作为一个文档，返回文档中指定field出现次数超过10的文档

大家好，拜托帮我看下吧谢谢！

就是求field（produce） 出现次数大于10 的文档，应该能实现的吧？我看官方文档aggregation 那块介绍的太多了，一时没找到，有大佬帮忙看看吗？万分感谢
比如 produce=牙膏  或者   牙刷  或者  抽纸  之类的，返回在es中出现次数大于10 的 商品的 数量


回复：

举例如下：把
"min_doc_count":4
换成
"min_doc_count":10 就可以了。
```
PUT product
{
  "mappings": {
    "properties": {
      "name":{
        "type":"keyword"
      }
    }
  }
}

POST product/_bulk
{"index":{"_id":1}}
{"name":"牙膏"}
{"index":{"_id":2}}
{"name":"牙刷"}
{"index":{"_id":3}}
{"name":"抽纸"}
{"index":{"_id":4}}
{"name":"牙膏"}
{"index":{"_id":5}}
{"name":"牙膏"}
{"index":{"_id":6}}
{"name":"牙膏"}

POST product/_search
{
  "size":0,
  "aggs": {
    "name_aggs": {
      "terms": {
        "field":"name",
        "min_doc_count":4
      }
    }
  }
}
```

# 2、推荐：doc values 与 field data 的一些知识整理

推荐阅读：https://elasticsearch.cn/question/9325

doc_value:保存在磁盘中，适用于String（text，keyword）类型，还适用于integer/long/float/double/date 类型等， 而fielddata 只适用于text类型

fielddata:保存在内存中，适用于text类型


# 3、logstash 正则表达式 正确写法

https://elasticsearch.cn/question/9320

老师好：日志如下：
2020-02-19 10:58:14.325 - [d24692bfc49c440f83a2af3cbd4d8e32///nonautoBack/undwrt/updateImmdLevel] - 更新任务紧急程度耗时:[12]ms
 
想通过正则匹配出：时间，d24692bfc49c440f83a2af3cbd4d8e32，nonautoBack/undwrt/updateImmdLevel，更新任务紧急程度耗时，12这几个字段。

尝试使用：%{GREEDYDATA} - \[%{USERNAME:traceid}\/\/\/%{USERNAME:methodName}\] - \[%{[\u4e00-\u9Fa5]+}:name\]:\[%{NUMBER:proceedTime}\]
但是一直没有出来，请教老师帮忙看下。

【回复ok】正确写法：

%{TIMESTAMP_ISO8601:LogDate} - \[(?<username>[0-9A-Za-z]+)///(?<path>[A-Za-z]+/[A-Za-z]+/[A-Za-z]+)\] - (?<desc>.*):\[(?<ms>\d+)\]ms
 
可以參考這樣寫法 感謝!

# 4、ES超大数据集群方案请教

现状： ES数据总量100亿左右， 磁盘占用约6T 

目前有32核 64G内存的机器若干（15台左右），SSD。 

ES内存打算分配20G左右，15台主机可用的os cache 大约在600G左右 ，

这样的话 只有约1/10的数据能被os 缓存，90%的数据都在磁盘，这样是不是机器配置远远不够？ 有没有更好的集群方案？

【**Medcl】回复：

够不够要看你的需求，除了存储，还有考虑查询响应时间和索引吞吐的需求。

Elasticsearch 基于 Mmap 的方式读取文件，是按需加载，不需要全部缓存在内存里面的。

建议实际压测一下，才知道是否达到你的需求。

# 5、Elasticsearch经常报429错且数据量锐减

当前数据有3个节点，服务器都是6核。每天的数据量在400万左右，开始的时候运行正常。最近经常报429错，而且数据量锐减。线程池大小为7，reject_queue为1000。

请教各位大神，可能是哪里出了问题呢？该如何处理啊？万分感谢

【回复】

如果被reject了，可以适当加大池大小，可以存多一点。

根本方法还得提高硬件处理能力。

https://elasticsearch.cn/question/9315

# 6、ES SQL怎么查询Join字段

【回复】

不支持

官方回复：You can’t do joins with elasticsearch.

Better to think your model differently and denormalize your data.

Parent/child feature is kind of 1-n relationship but I’d only use it if absolutely necessary.

https://elasticsearch.cn/question/9316

# 7、script_fields怎么访问父文档属性

环境：ES7.5
 
问题：怎么访问myparent中的其他属性，现在默认拿的是父文档id，我想拿 其他属性。求支招...............
 
 ```
 "script_fields": {
    "parent": {
      "script": {
        "source": "doc['join#myparent']"
      }
    }
  }
 ```
 
 【回复】
 拿不到的。
 
 脚本里面不支持从子对象里面拿父对象的字段。
 
 聚合不了，es 不支持
 
 # 8、es集群机器 内存使用的一些思考 
 
 堆内存建议一看：https://elasticsearch.cn/question/9327
 
 https://juejin.im/post/5d35ae896fb9a07ed8428046
 
 
 es是使用的堆内内存，而lucene 使用的 堆外内存。
 
elastic 的 Node Query Cache ，Shard Request Cache，Shard Request Cache 都是给查询结果使用的，Indexing Buffer 是存储新的插入文档使用的；

而 lucence的os cache 纯粹是让 倒排索引能加载到内存中 供与 查询 ，

所以总结就是  es 与luncene 一般是 各占一半内存，但是如果你的es集群 插入业务比较多，建议将jvm 内存增大，如果es集群的查询业务比较多，建议jvm内存 减少一些，让操作系统剩余使用物理内存多一些。

# 9、求指教：如何在docker中配置logstash多实例，去消费kafka中的同一个topic

问题：

在docker上部署了elk,想要使用logstash去消费kafka中topic的数据，发现消费的速度跟不上生产的速度，目前想配置多个logstash去消费同一个topic中的数据，

topic中已经建立4个partition。请问：是在docker下启动多个logstash的contariner吗？假如是的话，docker run的时候配置文件路径需要更改吗？

多个logstash实例共用的同一个config文件还是不同的文件


【回复】：

logstash是出了名的低效率。不如自己用其它语言写一个消费者。普通笔记本开个CentOS虚拟机（4G内存，所有软件在这虚拟机运行），单线程都可以每秒消费50K，并导入ES。多线程轻松上100K。就算用python把日志 json格式化之后，写日志到文件里，再由filebeat直接对接到ES都几十K。
 
filebeat ---- kafka  ----- python(json格式化 file) -----filebeat-----ES  (简单)
 
或者
 
filebeat ---- kafka  ----- python(json格式化）  ---ES  （稍复杂，需要调用ES接口写入数据)

https://elasticsearch.cn/question/9348




