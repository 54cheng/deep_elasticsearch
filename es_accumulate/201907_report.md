# 1、es的index.max_result_window设置会过期吗？
回复：建议索引模板里设置实现。
https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html

# 2、ES集群节点更换时，数据迁移的疑问

https://elasticsearch.cn/question/7871

我的ES是用来放日志的，按天创建索引。数据节点有10台
目前的需求是默认打开最近3天的日志，3天前到前30天这段时间的日志都是关闭状态。
这种情况下，如果要下线一个或多个节点会很头疼：
首先设置allocation.exclude._ip排除掉这台机器后，它只会将已经打开的索引分片迁移到其他服务器，关闭状态的索引是不动的，如果要把这台上的分片全部迁走，
得打开所有已经关闭的索引等数据迁移后再关闭。
另外就是这些分片的迁移本身就是很费时的。即使我有脚本能自动操作也是要等很久。

请问这种情况下有没有比较好的解决方案呢。

我的想法是，每6天为一组，连续六天的索引设置分片只分配在其中2台节点上。轮转着这样保存。假如某台我需要从集群中下掉节点，可以找存放日志最早的两台中的一台来下线。
即使不做数据迁移，也只会丢失最早最不太可能用到的日志。如果要做迁移的话，也只需要打开6天的索引做操作。
但这种方法有个问题，就是每天只有2台节点在做数据写入，负载比10台平均处理所有写入请求要高了5倍 。

不知道还有没有其他更好的思路呢？

【Medcal回复】：如果你有副本的话，可以直接上最新的 7.2 版本，现在已经支持对关闭索引的自动均衡和副本，
https://github.com/elastic/elasticsearch/pull/39499

# 3、一个filebeat如何将数据输出到多个elasticsearch集群，保证两个集群的数据一致（起到备份作用）

1. 需求是需要将filebeat收集的日志，输出的两个elasticsearch集群中。并且保证两个集群中的数据都是一样的。
 
2. 测试
配置
    output.elasticsearch:
       hosts: ['192.168.223.26:9200','192.168.223.27:9200']
并不能实现需求，原因是官网上介绍说，这个是安装循环顺序往两个集群中写入数据。因此最终结果是，一份数据被写到了两个不同的集群中。两个集群的数据，完全不同。
 
3. 求问，有没有什么办法实现，filebeat将一份数据同时写到两个elasticsearch集群中去。

回复：你通过ES 进行备份撒……现在ES 7出了集群之间的复制功能。
换个思路……注意：同意楼上，es 备份应该使用 cross replica 或者 snapshot，而不是从数据源进行双写。

# 4、在dev-tools下执行delete_by_query是报错409或者超时

在dev-tools执行delete_by_query语句时，不是报超时，就是报409版本冲突，而且在url上已经加上了timeout，还是报超时，请大神指导

【回复】
超时是因为执行过程比较缓慢，可以增加wait_for_completion=false参数，通过返回的taskId检查是否完成

# 5、悬空索引(Dangling indices)无法删除

服务器运行环境信息: filebeat->kafka->logstash->es
 
软件版本： es:6.6.1；3个master+node；1个协调节点，共4个节点
 
背景：
    es集群因为之前升级的原因，集群成red状态，后来商量后，把变红的索引都删了，然后重启了下集群，分片分到8000多的时候，就不往下分了，查看了下未分配的索引都是之前删除过的，再一次删除red索引后，发现过会儿又会出现，而且通过_cat/indices查不到该索引，但是查看未分配的分片中又可以看到改索引的名字，协调节点一直在报can not be imported as a dangling index, as an index with the same name and UUID exist in the index tombstones. This situation is likely caused by copying over the data directory for an index that was previously deleted
 
由于这个集群之前是其他小伙伴维护的，问了后，之前有物理删除过某个red索引的uuid目录，在github上看到一篇关于悬空索引的文章，https://github.com/elastic/ela ... 18250
 
现状：
    现在集群也不影响使用，就是一直是red状态，已经好几个月了，索引创建周期是按周
 
有老师或者朋友遇到过类似的问题不？

【回复】
在硬盘上面找找那个索引对应的data目录下面存放的内容。把他删除了。
要不就是你有节点离线很久了。这个索引都删除了，重新加入的节点还保存有这个信息。

解决方案：老师好，按照您的方法，我这集群green了，解决办法是先按照老师的说的方法把/data目录下的内容删了，然后再用脚本跑了一遍删除未分配的索引，之前时删不掉，现在是可以删掉了，集群已经green，感谢老师。

# 6、ES和oracle数据库同步方案请教

数据量大概几百G，使用elasticsearch实现全文检索。
网上找了ES和oracle数据库同步方案好像普遍都是logstash，但是logstash在大数据量时性能并不好，各位大佬有更好的同步方案吗？

【Medcl推荐】GoldenGate 支持 ES，可以试试。https://blogs.oracle.com/dataintegration/oracle-goldengate-adapter-for-elasticsearch

# 7、【OOM问题】使用javaAPI上传1gb,共350000份文档，发生OOM

使用bulkprocessor，bulkactions为1000，size为20mb,经过多次实验，总是上传到340000就发生oom,弄了一天也没弄好，新人求救

【回复】
应该是索引的 refresh 设置的有问题吧
写入的时候关闭 refresh 是可以提高速度，但是长时间不 refresh 会造成 oom

# 8、logstash消费多个topic

我们这的场景是每个日志在一个topic中，logstash应该是写多个kafka-input 还是直接每个topic对应启动一个logstash实例

【回复】
可以监听多个topic吧topics => ["topic1","topic2","topic3","topic4"]

【Medcl】使用 topics_pattern 支持正则来批量。还要记得设置 metadata_max_age_ms 来获取后续 topic 的变化。

# 9、能否在一个查询中 查询两个条件 在对两个结果进行除法计算

请教各位一个问题，我们有一个场景，想通过1个查询语句，计算两个查询结果的除法，比如，我有一个查询条件，用 idc: "BJ" 能统计出有100条数据符合要求 ，第二个条件 idc: "SH"，能统计出有200个数据，我现在想要取到  100 / 200 这个值  50% 这个数据，请问能有办法实现吗？请各位大神指点一下。

#参考 es6.6版本

```
PUT test01_index/_doc/5
{
  "x_value":15,
  "y_value":3
}


POST test01_index/_doc/_search
{
  "script_fields": {
    "my_divide_field": {
      "script": {
        "lang": "expression",
        "source": "doc['y_value'].value != 0 ? doc['x_value'].value / doc['y_value'].value : 0"
      }
    }
  }
}

```   

# 10、大概10几TB的数据，要求查询时间在2s以内，可以实现吗，应该怎么进行优化？
现在的数据量只有10几G，查询测试大概满足要求，但不是很稳定，以后数据扩展到10几TB，肯定就满足不了了。

【回复】
看楼上你的机器配置，很明显你是没有上生产环境的，这个机器配置严重的不合理，其中内存太小，硬盘太大了，根据你的使用需求，你可以多加几台机器，机器的数量多了以后性能会好些，但是每台机器的内存可以放到32G-64G，当然了，如果你的机器特别多，也是可以放到16G的。硬盘的话，每台机器的硬盘根据你的内存大小来配置，建议不要超过2T。这是从硬件上来说的，想要性能好，软件设计上就依照@ridethewind说的就行。

建议从以下的几个方面去考虑：
1. 根据业务的字段合理的设置_routing 
2. 合理的定义mappings，该用keyword还是该用text,该用什么分词器，不参与检索的字段不要分词
3. 查询范围尽可能小
4. 只读索引及时段合并

推荐：https://elastic.blog.csdn.net/article/details/85109769
https://elastic.blog.csdn.net/article/details/97695931

# 11、来自不同输入源的日志（有不同的index名称），出现在一个index里，请教怎么处理

我这样写piplines.yml：
```
- pipeline.id: sip_logs
  path.config: "/etc/logstash/conf.d/ouyu-sip_logs.conf"

- pipeline.id: conf_logs
  path.config: "/etc/logstash/conf.d/ouyu-conf_logs.conf"
```
观察了一下日志，两个index的日志不再重复了，各自只显示来自相应syslog的数据，达到我的目的了，非常感谢 @medcl。

https://elasticsearch.cn/question/7911

# 12、es7.0.0版本的TransportClient已经弃用了吗
【Medcl】注意：对头，别用 TransportClient 了。

The TransportClient is deprecated in favour of the Java High Level REST Client and will be removed in Elasticsearch 8.0. The migration guide describes all the steps needed to migrate. 
https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.0/java-api.html
 
7.0废弃，8.0移除

# 13、升级7.2后 max_shards_per_node 参数总是丢失

我的系统在升级7.2后 要求总的分片数不能超过3000

我通过下面的方式给他设置为了10000
```
PUT /_cluster/settings
{
"transient": {
"cluster": {
"max_shards_per_node":10000
}
}
}
```
 
然后logstash就可以正常写入了 ，但是这个参数总是丢失，所以每天都要重新设置一下
 
我想问的是 有什么拌饭能够将这个参数设置死不要总是调 要不然日志总会丢失
 
我尝试在elasticsearch.yml中增加了一个参数：cluster.routing.allocation.total_shards_per_node: 10000

但是没有效果

【回复】：transient 的参数是临时生效的，重启后丢失,
你把transient  ->  persistents试试

# 14、【写入均衡】es存储data多路径，会不会根据多路径的存储大小，均衡存储写入

es存储data多路径，会不会根据多路径的存储大小，均衡存储写入

【回复】
es中索引分成shard来进行存储，排序规则是这样的
1.  判断每个path下该索引的shard数，优先返回含有本索引的shard数最少的path
2.  当1条件结果相同，对比每个path中包含有的shard总数（所有索引的），返回包含shard数最少的path
3.  当2条件结果相同，对比可用空间，返回可用空间最大的path

# 15、如何将一个大的index根据日期拆分成每周一个小index

ES 6.4
有一个70+GB的index,如何根据index内部document的创建日期将其拆分成很多小的index?
希望同一周的document成为一个新的小index.

【回复】
借助rollover+curator实现索引的切分和索引的生命周期管理
https://elastic.blog.csdn.net/article/details/81432646

# 16、ELK 7.2 启用安全认证功能后 API如何连接ELK做查询

我的ELK7.2集群启用认证功能后，我该如何用REST API连接集群？是不是curl就不能使用了

【回复】
增加鉴权认证就好，REST CLIENT 有对应的方法，curl 增加-u{username}:{password} 参数

腾讯云Elasticsearch最佳实践：https://cloud.tencent.com/document/product/845/19538


# 17、如何根据数据某字段值的不同，调用不同的正则表达式？

业务系统会输出两种格式稍有不同的数据到logstash：

在filter里如何写grok，可以根据数据的第一个单词是"OuYu"或者"OpenSIPS"，分别调用不同的正则表达式语句来过滤这些数据？

```
if "OuYu" in [message] {
   grok {  } 
}else { 
   grok { }
 } 
 ```
 
 # 18、logstash获取数据的时候，能否指定数据类型？
 
 能否在Logstash的input、filter或output里指定数据类型，希望获取日期数据的时候，把它的类型指定为date，而不是默认的text。
ELK是最新的7.0版本。

刚刚把这个问题解决，自己回答一下：
不能在Logstash的input、filter、output里指定数据类型，我在es里为这个索引建立了一个索引模板，在模板里指定字段的类型，我把一个字段指定为date，另一个字段指定为ip，再删除和重建index，然后在mapping里可以看到这两个字段的类型已经改变，并且可以正常接收和显示数据。

# 19、针对词库更新后需要重建索引, 用 reindex 命令跟我查库后 upsert 全量更新有啥区别吗

针对词库热更新我是用 ik 配合 nginx 实现的, 很好用
 
针对重建索引我之前一直是是先查数据库, 然后走 batch upsert 无脑更新 index 中的所有 document
 
而 reindex 命令最近我刚接触, 发现使用方式是结合 alias 来使用, 流程:
1 alias 指向老index
2 热更新词库
3. 创建新index的mapping/setting
4 reindex, source=老index, dest=新index (记住当前时间点 time1)
5 alias执行add/remove来指向新index (记住当前完成时间点 time2)
6 将 time2 - time1 之间的增量数据插入到新index
7 删除老index
 
这个方案的缺点是步骤4中 reindex 的时候是先生成一个 snapshot, 因此全部完事后还得有步骤6来导入增量数据, 真是太麻烦了, 无法一键完成
 
请问: 我无脑 upsert 跟 reindex 有什么区别吗? 我知道时间肯定是 reindex 快一些, 不过我全量查库的时候走的是牛逼的主键分页模式, 不存在任何性能问题, 请大佬帮忙解答下, 谢谢

【回复】
不存在本质区别，都是获取原始数据重新索引进es。但是如果可以从其他库里查询全量的话，还是建议走全量库重建的方式。
1. reindex比较麻烦，需要不停的追增量数据
2. reindex不一定会更快，尤其是同集群内做reindex，因为ES集群内会同时存在读写资源的消耗，读写频率控制不好会影响其他索引的读写
3. alias和reindex无关，使用其他方式重建同样可以使用

谢谢, 经过这两天的使用我的经验就是, alias是必须要用的否则会影响业务, 如果读数据库后直接在原index执行upsert, 无法删除老数据, 因为他只是insert和update, 而reindex和读数据库都需要处理增量数据, 因为在切alias指向之前一定是有增量数据没插入新index的情况的, 因此我的结论是, reindex的时间比读数据库再创建index快了好多倍, 因此最终我还是选择 reindex 结合 alias的形式

更多深入探究待继续：https://elasticsearch.cn/question/7800

# 20、使用filter + composite aggregation的问题
需求：先得到最近1小时的数据，然后用composite aggregation的方法实现ouyu-number字段的分页输出功能：

```
GET /bj-sip_register/_search
{
  "size": 0,
  "aggs": {
    "number": {
      "filter": {
        "range": {
         "@timestamp" :{ 
           "gte":"now-1h",
           "lt":"now"
         }
        }
      },
      "aggs": {
        "y": {
          "terms": {
            "field": "ouyu-number.keyword",
            "size": 20
          },
          "aggs": {
            "sales_bucket_sort": {
              "bucket_sort": {
                "sort": [
                  {
                    "_key": {
                      "order": "asc"
                    }
                  }
                ],
                "from": 0
              }
            }
          }
        }
      }
    }
  }
}
```
待深究讨论：https://elasticsearch.cn/question/8000  聚合后分页实现

# 21、es可以做读写分离吗？

因为写都是往主分片中写嘛。。比如我有10台服务器，10个节点。可不可以规定所有的主分片都在1，2，3节点；而所有的副分片都在另外的7个节点。这样写都会用1，2，3节点的cpu，不影响其他7个节点的读服务。


冷热分离实践：https://blog.csdn.net/jiao_fuyou/article/details/50511255
更多配置需要参考最新官网。

# 22、ES-hadoop如何衔接es跟hadoop

各位大神好～～之前未接触过Hadoop，
现在有一现成的HDFS，中有数据。要用Elasticsearch搜索Hadoop中的数据，我查了各方面的资料，得知要用ES—Hadoop。可是官网介绍资料有限，ES-hadoop的安装步骤只有三步：
下载解压、添加到Hadoop、然后就可以用了。求问
1、如何添加到Hadoop？？
2、我看其它文章介绍，最后运行hadoop jar eshadoop.jar H2EJob /user/data/es/job，ES-hadoop下完解压全是文件夹，里头包含.java源代码。难道是要我把它编译成.jar文件吗？


【Medcl回复】：
下载地址：https://www.elastic.co/downloads/hadoop
不知道你之前用过Hadoop木有？ES-Hadoop就是一个Hadoop里面的任务，使用方式和Hadoop常规执行任务的方式是一样的，这里面如果运行遇到什么问题，可能和Hadoop的配置或者环境有关系，需要看看具体异常才知道什么问题。

# 23、别名查询多个索引的原理，多个索引并发执行吗？

查询实际上是查询shard，多个shard可以并行的执行查询，查询多个索引会向这些索引下的所有shard发起查询请求，可以并行执行

# 24、elasticsearch最大返回值问题
如图，es最大返回值已经成功修改为20亿了，为何查询后返回最大值还是10000？版本7.1.1

【回复】
你想要的是hits的总数，默认的话es对于10000以上的查询结果只显示10000，不会显示准确的数量。这个是通过track_total_hits控制的，设置为true的时候就是获取准确的结果数，也可以设置为int类型的数字来代表具体阈值，超过阈值将只显示阈值的数量
```
GET twitter/_search
{
"track_total_hits": true,
"query": {
"match" : {
"message" : "Elasticsearch"
}
}
}
```

# 25、问题一：集群在数据写入过程中为什么会有分片数据不自动均衡分配的现象？ 
问题二：设置每个索引在一个节点的最大分片数量是否会解决这个问题？ 
问题三：已经分配失败的分片，如何快速恢复呢？

我现在有一个六节点的集群，角色配置是data=true,master=true。（索引分片分配方式为：六个分片或四个分片）在线上使用过程中发现（正常使用几周后发现的），

集群的负载不均衡，有两个节点的DISK使用量接近98%，其它节点磁盘还有较多剩余。集群看到的现象是磁盘爆满的这两个节点的分片都处于未分配的状态【"details": "failed to create shard, failure IOException[No space left on device]"】。

之后在集群上新建6个分片的索引的时候，甚至有些索引的分片全在一个节点上。

另外mapping设置的flush_threshold_size为1.6GB，服务器机器内存都是32G，硬盘200G。

【回复】：
通过设置total_shards_per_node来均衡分片的分布 https://www.elastic.co/guide/e ... .html；
另外通过GET _cluster/settings看下是否特殊的设置导致分片分布不均

# 26、elasticsearch利用script获取nested类型数据并计算怎么实现？
【回复】

省略部分参考楼上script_field的用法。
doc['my_field'].value 和
params['_source']['my_field']. 的用法。
后者会加载到内存呢，会更快。
```
{
   "nested": {
      "path": "companies",
      "score_mode": "sum",
      "query": {}.
      "inner_hits": {
         "script_fields": {
           "overlap" : {
             "script": {
               "source": "................................",
               "params": {
                   "from": "2012-01-01",
                    "to": "2015-06-30"
               }
             }
           }                
         }     
      }
   }              
}
```


# 27、好文推荐1：自研Mysql到Elasticsearch框架：es-common实践经验分享（系列文章）
https://elasticsearch.cn/article/13415

# 28、好文推荐2：ES6.8权限使用配置 实践-含截图
https://elasticsearch.cn/article/13432



