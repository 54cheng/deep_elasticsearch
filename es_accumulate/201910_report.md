# 1、Logstash服务启动为什么会把Elasticsearch服务杀死？
使用bin/logstash -e 'input { stdin { } } output { elasticsearch { hosts => ["XX.XXX.XX:9200"] } stdout { codec => rubydebug }}'来启动服务，
为什么Elasticsearch会显示Killed

回复：
logstash 非常耗费资源，估计是你的es和logstash 都按照在同一台服务器，而服务器的配置并不高，所以跑logstash 就可能把es弄挂。

# 2、如何判断Elasticsearch的字段是否是数组

回复：Elasticsearch没有专门的数组类型，ES同一字段，普通类型和数组是可以同时存在。
转入java对象，我也没有准确来判断这个类型是数组还是普通类型。目前是这样处理的，java对象中对应的字段设置为List类型，这样2种类型都可以兼容。

# 3、DSL语法的执行顺序
```
{
    "query":{
        "bool":{
            "must":{
                "match":{
                    "state":"PA"
                }
            },
            "filter":{
                "range":{
                    "age":{
                        "lte":100
                    }
                }
            }
        }
    }
}
```
是先执行match还是先执行filter？内部的执行顺序和代码的书写顺序有关系么？

回复：
官方博客——https://www.elastic.co/cn/blog/elasticsearch-query-execution-order

核心：
Do filters get executed before or after queries?
A: Neither, really. Everything is interleaved, regardless of whether they are queries of filters. 
Conjunctions get executed in a way where the clause with the least cost is used to lead iteration and other clauses are advanced 
to check whether they match too. However we only compute scores when we verified that all clauses match.

# 4、Elasticsearch集群规划求助

各位小伙伴好，我想请教一下关于集群规划的问题…

数据量大概有30T(在开了副本的情况下)左右，目前有7100个分片(算上了副本分片)。

集群有15台机器，每个机器的内存都是125G。

我打算单独把一个节点分离出来，作为master节点，之后再将两个节点作为协调节点，剩下的12个节点，6个给热数据6个给冷数据做冷热分离。

请问下各位小伙伴我这个规划有没有什么问题，可以的话希望指正！

另外我想问一下…我经常看到网上有人说自己的集群里有2、3个主节点，但是主节点无论有几个，最后不还是只有一个能当选么，那这样干脆拿一台节点出来只做主节点不好么？为啥还要保持有2、3个呢？是担心主节点挂掉么？

还有就是一旦开了协调节点，是不是我的程序里，连接ES集群的代码就必须只能连接两个协调节点了(以前都是直接把所有节点写在client配置里)？

回复1：1，分片数量多少合适？
每个分片的大小推荐在20GB-40GB之间，我自己一般保证单个分片的大小不超过30GB。每个节点上多少个分片合适？

这里有一个很好的经验法则：确保对于节点上已配置的每个 GB，将分片数量保持在 20 以下。如果某个节点拥有 30GB 的堆内存，那其最多可有 600 个分片，但是在此限值范围内，您设置的分片数量越少，效果就越好。

具体参考：how-many-shards-should-i-have-in-my-elasticsearch-cluster
粗略地算：（30*1024)/7100=4.3GB/分片，每个分片的大小不算大，能hold住。
具体到一个索引应该配置多少个主分片，多少个副本分片？考虑一下这个索引是用来干什么的？这个索引的Mapping结构如何定义？
哪些字段需要做搜索(index_options参数)？哪些字段做term查询(keyword 类型)、哪些字段需要Analyzer做Match查询(text 类型)、要不要聚合(是否开启doc_value)，要不要语法高亮(term_vector 和 positions 参数)，要不要禁用_source参数？
一个合理的Mapping配置也是能够有效减少index 大小的。我们实际生产环境中，禁用doc_value之后，索引大小几乎减小了一半。
 
 像这种128GB大内存的机器，ES官方文档heap size里面有说：ES进程所使用的物理内存(Xms Xmx配置)不要超过机器物理内存的一半，
 同时考虑到指针压缩问题，分配给ES进程的内存不要超过32GB，一个安全的值是26GB（各个操作系统平台上，JVM进程26GB不会有指针压缩问题）
具体参考：heap-size

2，关于主节点个数的问题
"网上说的配置3个主节点"，我的理解是：3个 master eligible node （有资格成功master节点），通俗地讲，就是拿3台机器出来，
不存储数据(node.data=false)，专门用来做master选举用(dedicated master eligible node)，选举结果肯定只能是：其中某台节点成为master节点。
如果整个集群中只有一台节点能够成为master节点，就会存在单点故障，如果master节点宕机，整个集群就再没有其他节点能够被选举为master了，会导致整个集群不可用，这就是为什么要在多个节点上配置多个 node.master: true
关于ElasticSearch各个节点所起的角色，可参考：modules-node
 
3，client连接协调节点问题
这个还是节点的角色问题。可参考第2点中给出的参考链接。注意这句话："Every node is implicitly a coordinating node."，如果要单独拿2台出来做协调节点，
需要在配置文件里面这样配置：
node.master: false
node.data: false
node.ingest: false
协调节点作用：将搜索请求转发到正确的节点上；将各个节点上搜索结果再次排序汇总成最终结果（query_then_fetch 查询类型）
 
其实我觉得，让每个节点单独扮演某个角色(master eligible node 、data node、coordinatoring node) 主要还是为了集群稳定吧，各个功能模块各司其职，
最好互不影响。

回复2：
1.存在15台主机，每台主机存在有126G的大小，其实这种情况可以考虑每个主机多es实例进行部署，可以更加合理的利用主机的内存
2.冷热分离的本质实际上是为了把经常搜索的数据放到io更好，性能更好的磁盘上，这里面要取决于主机上是存在不同的性能磁盘还是主机有不同磁盘的性能数据来看，
可以采用多实例挂在不同的目录，将热索引的数据按照tag将分片存放到io更好的磁盘中，再使用curator之类的工具或者es原生的move之类的api进行热热冷数据的迁移
 3.另外需要看实时写入es的索引的数据，如果只有1个索引比较简单，可以直接均衡将索引的分片均衡分布，如果实时产生的索引比较多的时候，
 每个索引由于大小不一致分片配置也不一样，需要有1个合理的机制将全部的分片均衡分布
 
 # 5、多种场景下的融合搜索有什么比较合理的方案呢？
 
 比如有三种数据`联系人`、`新闻`、`项目文档`，搜索`王伟`，在三种数据中都会有出现。
 
问题有:
1. 不同数据独立索引，还是有一个`综合索引`？
2. 不断有新场景引入的情况下，怎么控制搜索范围？
3. 不同数据量级差异较大，如何设计索引切割比较合理？

回复：

为了低耦合，建议分索引，问题2和3也没了。同时务必做好以下两点：
（1）保持好“一场景一索引”的原则。
（2）所有索引字段对齐，没有数据的字段置空而非null值。
不按上面做，后续会有以下痛点：
（1）“多场景一索引”很多人会有type区分索引，这样会导致查询时做不了以索引区分权重。比如你想让“联系人”权重更高，一索引情况下做不了（可以做，但比较麻烦）。
（2）多索引没对齐字段以及没有数据的字段不置空而是null值，查询时script_score会报错。比如_search/index1,index2时，index2里没有某个字段或某字段是null，script_score都会报错导致查询请求失败。
所以一开始就做好规范吧，曾ES接入过100+个场景的建议。

https://elasticsearch.cn/question/8486

# 6、ES Aggs根据聚合的结果（数值）进行过滤

聚合实操案例：https://elasticsearch.cn/article/13501

# 7、elastic search 如何向list字段里面追加数据

```
POST test/_doc
{
  "f1": ["d1"]
}


POST test/_doc/_update_by_query?pretty
{
  "script": {
    "inline": "ctx._source.f1.add(params.hits)",
    "params": {
      "hits": "d2"
    }
  },
  "query": {
    "match_all": {}
  }
}

GET test/_search
```

# 8、【重要】Elasticsearch升级后如何回滚？
ES6.1升级到6.7版本后（直接替换二进制），服务正常。但如果想回退到6.1版本，发现数据文件内容、结构都有调整，历史版本不识别，
除了备份之外，还有什么办法可以降级吗？

回复：
版本升级直接替换二进制文件，这操作....心太大了。
正规方式：数据备份、部署新版本ES集群、重建索引。
特别是涉及大版本更新，mapping、查询DSL、插件很多要跟着一起修改。
https://elasticsearch.cn/question/8495

# 9、新手求教，这种数据适合ES处理么？

比如，我有10个csv文件，有着不同的字段结构，通过一个UID字段将他们关联起来，类似下面这样
test1.csv结构
UID,FieldA,FieldB,FieldC
1,AAA,BBB,CCC
 
test2.csv结构
UID,FieldD,FieldE,FieldF
1,DDD,EEE,FFF
 
不知道这种数据适合ELK处理么？现在的想法是把10个csv导入到10个索引，因为查询涉及到通过UID关联查询，
ES方便做到这种关联查询么？也不知道这种做法是否正确。还是说要将10个csv的字段合并成1个索引来存？

回复：
关系型数据库转到ES，大多会涉及多表查询的问题，想做到像sql那样的联合查询，一般4种方法:
1. 多个索引库，java客户端实现查询联合，使用于数据量很小，多次去请求，客户端整合返回结果。这个局限性很大。
es没有索引库之间的关联查询，下面都是一个表，来实现联合查询；

2.宽表，所有层数据都展开；查询方便，但是维护麻烦，删除和修改有诸多不变；而且占用空间大。

3.嵌套;1对多，多对多都可以实现；但是嵌套层数不要太深；更新数据时，是整个文档都要更新索引，更新不能太频繁；关联就靠嵌套关系，没有什么关联开销

4.父子文档:父与子文档分开，join字段的关系连接，这个最像sql；关联查询也有巨大的性能开销；
 
具体到你的10的表：1. 能合并的合并，像id+name这类的小表合并到大表里面；
                              2.1对多，多对多，很少修改的做好使用嵌套，像订单与订单项这样的表，；
                              3.表关系进一步分析，没什么关联的拆分出去；
不是说10个就建10个索引，或者合起来建1个；具体还是需要看表与表的关系；做不同区分；
 
 # 10、如何对相关度分进行归一?
 
 如下面的查询语句，我想在文本匹配分的基础上增加一个类目预测的分数。但是类目预测的分数是一个固定值，而文本匹配的分数变化幅度可能很大，
 这就导致类目预测的分数权重不好确定。因此我想对主查询的分数进行归一化处理，请问在script_score里面能否获取到query的最大分数max_score? 
 或者是否有其他的方法能实现这个功能？ 
 
 medcl回复：
 max_score 没有办法在这个上下文里面得到，你用 decay function 来平滑得分的区间可能更好。
 
 https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html#_supported_decay_functions
 
 # 11、kibana中设置通过微信报警
 
 自己编写一个能够通过微信公众号/企业号发消息的程序，给一个http restful接口出来。
然后watcher通过http触发这个接口就好了。数据格式你可以自己定义。

# 12、ElasticSearch如何平稳的做数据迁移？

阿里云的迁移很详细：https://help.aliyun.com/knowledge_detail/61145.html?spm=5176.13394938.0.0.291d1f7cj7x0Mr
借助：reindex 脚本实现。

其他铭毅推荐：elasticdump

# 13、【推荐】不规则的产品编号该如何进行分词呢

有商品编号id是一些字母加数字加符号组成的字符串，该如何进行分词？
 
例如id 是 STM8_S003F3P6  输入  STM8_S003F3P6，STM8，S003F3P6，S003，F3P6  都能搜索出来结果来
 
写了个ngram 让它类似去穷举的索引分词，然后搜索分词就简单一些， 这样子的做法是可行，或者还有更好的办法吗？
 ```
 "tokenizer": {
        "ngram_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 10,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
      
       "analyzer": {
        "index_analyzer": {
          "tokenizer": "ngram_tokenizer",
          "filter": [
            "lowercase"
          ]
        },
        "search_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        }
      }
    }
  ```
  
  medcl回复：可行，前缀查询多的话，可以再配一个 edge_ngram
  https://elasticsearch.cn/question/8547
  
  # 14、【更新场景】es5.3.2版本，目前有业务需求每天24不断更新es文档中的某个字段，导致es更新效率越来越慢
  
  目前有需求要每天24小时不断更新es文档中的某个字段（处理文章的相似问题，给相似系列的最新文章打标识），模型用的nested。
  用的批量更新的api进行的，频繁更新一段时间后发现es更新速度越来越慢，测试发现刚开始更新五个id还只有0.2秒左右，
  连续多点几次更新五个id最后几次会花费3秒左右，
  各位大佬有木有什么好方法或者新思路。
  
  【回复】
可以通过hot_thread (https://www.elastic.co/guide/e ... s.html) 看看性能主要卡在哪里了

随着文档越来越多，更新的代价越来越大，ES不太适合频繁更新的场景

铭毅：这个问题需要结合实际业务，好好讨论一下。 溯源为什么ES不支持频繁更新？

# 15、数据量小，性能要求高，求推荐集群配置

小白求助，下面这种需求如何搭建集群比较合适
1）200万数据，排序查询、 并发500 + 200万数据按一个指标聚合（大概到4个聚合到一个），并发500 ：
2）400万数据， 排序查询， 并发1200+ 400万数据按一个指标聚合（大概到4个聚合到一个），并发1200 ：

回复：
评估集群规模考虑的因素：
1、当前存储：数据总量——有提供 400W
2、未来存储：数据增量
需要集合1,2，需要你补充：单条数据大小，给出数据占据的存储大小，并且预留未来扩展？
3、性能指标，你有提到并发1200——对cpu有较高要求
4、复杂功能，你有提到一个指标聚合——不算复杂，内存适中就能搞定
 
你可以拿到机器后，借助：esrally跑一下性能，结合实际硬件性能为准。

# 16、es高亮在项目中该怎么使用？

我发现高亮会作为一个对象，单独返回，不会改变source中的值，那我返回到前端，该怎么显示呢？前端要展示该字段，
取source里的值吧，没高亮标签，取高亮对象的值吧，又缺失未高亮的数据，因为该字段是多值。那么高亮功能到底该怎样用呢？

https://elasticsearch.cn/question/8564

官方不支持这种方式，几年前就有人提bug，官方没有解决。
https://github.com/elastic/elasticsearch/issues/7416
 
网友的实现替代方案：

[ "1", "2", "3" ] [ "Alice", "John Doe", "Bob" 
]instead of using objects with ID
[{id:"1", name: "Alice"}, {id:"2", name: "John Doe"}, {id: "3", name:"Bob"} ]

# 17、Elasticsearch：inverted index，doc_values及source

Elasticsearch的每个shard里实际上是一个Lucene的索引。
在这个索引里，它包含每个文档的inverted index, doc_values及source。
在实际的使用中，我们该如何管理它们，比如对有的字段不进行索引，或者为了节省空间，不存储doc_values，对于某些字段不进行存储等

https://blog.csdn.net/UbuntuTouch/article/details/102642703

# 18、ES相关度评分不符合预期

ES相关度评分有三个参数不太明白，我录入了两条数据，分别为：
{"id":"2","enName":"bad apple can't be eaten"}、{"id":"1","enName":"bad apple"}，
根据相关资料，一个字段包含的词项数越少，得分越高，所以我以为搜索"apple"的时候，id为1的数据得分会高于id为2的数据，
但是最终结果两条数据得分一致。查看词频(TF)打分公式(freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength))，
发现fieldLength和avgFieldLength始终相等，这导致不管字段有多长，最终值都是1.0，这是怎么回事呢？
另外查看逆文档频率(IDF)，发现语料库的文档总数(docCount)和包含该词的文档数(docFreq)也永远为1.0。各位大佬有知道怎么回事的吗？

回复：
打分只能发生在具体每个Shard上，因为每个Shard都是一个全局索引，这是引擎设计的，配合建索引阶段Shard文档量负载均衡所有文档时这些参数都会接近相等。
所以，文档量少到一定程度时，有两种方式可以解决参数值不一致的问题：
（1）search_type=dfs_query_then_fetch，相当于计算时会去计算所有Shard上的参数值，实时计算取值，比较慢；
（2）preference=_primary，只在主分片上倒排求交，没有利用副本分片做计算，不算慢。
建议用第二种。

# 19、reindex异常终止，怎么在断点继续执行？
回复：

生产环境迁移，使用reindex操作老数据迁移，同时生产也在往索引写数据，老数据迁移了好几天，由于网络问题导致reindex中断，不想重新reindex，该怎么操作？
使用默认的迁移脚本：
```
POST _reindex
{
"source": {
"remote": {
"host": "http://otherhost:9200&quot;,
"username": "user",
"password": "pass"
},
"index": "source",
"query": {
"match": {
"test": "data"
}
}
},
"dest": {
"index": "dest"
}
}
```
回复：
Settings op_type to create will cause _reindex to only create missing documents in the target index. All existing documents will cause a version conflict:
```
POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "op_type": "create"
  }
}
```

# 20、大家好请问带权重的综合搜索排名应该怎么设计数据和实现？

es 的教程看了很多了，但对于整体的设计还是一脸懵X。可能简单给我举例一下吗？
现在的需求就是普通的电商系统，要想根据销量、成交量、转换率等等做一个“综合排序”。那我想知道数据结构应该怎么进行设计？商品信息有修改，应该何时用什么方式同步 es 呢？望大家解答，感激不尽！！😁

回复：
几种思路仅供参考
1. 基础数据之外，冗余几个字段，比如销量、成交量、转换率，然后query的时候用script对这几个字段进行加权计算，比如：
return 召回得分 + 销量 / 1000 +  成交量 % 10 + 转换率 x 10
然后系统里起几个现成异步更新每个商品的这几个字段
 
2. 每个商品这几个字段存缓存，如redis，在搜索召回的时候，通过自定的公式 + 人工运营策略重新排序
 
 
 # 21、painless Number数据类型无法转换为String？
 回复：
 ```
 POST _scripts/painless/_execute
{
  "script": {
    "source": "Double.toString(Math.floor((params.a-params.b)/60))",
    "params": {
      "a": 70,
      "b": 10
    }
  }
}
```

# 22、count api 和 直接设置size = 0 ， 来统计条数的区别。

铭毅提醒——7.X要注意了。
官方提供了count api 来获取匹配的结果， 如下：
```
GET /twitter/tweet/_count
{
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}
```
那么，按照下面这种方法，和count 方法有何区别：
 ```
GET /twitter/tweet/_search
{
    "size": 0,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}
```
结果都可以得到相应的总的匹配的条数。 

回复：
如果只是文档计数，建议使用count api。
Es 7.x版本，search api为了性能，已经不返回准确的total hit，而是一个估算值。
 ```
search api
POST kibana_sample_data_logs/_search
{
  "size": 0,
  "query": {
    "match_all": {}
  }
}

//response
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 10000,  //>10000
      "relation" : "gte"
    },
    "max_score" : null,
    "hits" : [ ]
  }
}
```

https://elasticsearch.cn/question/8562
回复：在我的理解看来，count 和 hit 是两种类型的查询，count代表精确统计（和关系型数据库的count一致），
hit是从相关性的角度来统计的。hit表示，es检索到了和查询条件相关的文档，并按照相关性排序，返回topN，至于到底有多少文档和查询条件相关，
其实是不重要的。如果你确实想知道，track-toal-hits就派上了用场，当设置为true时，它会精确统计，当然也可以设置为一个阈值，它会告诉你实际值是否比阈值大。

试试将track_total_hits设置为true，而不是一个阈值。
When set to true the search response will always track the number of hits that match the query accurately.


推荐博文系列：

1、https://www.cnblogs.com/hapjin/p/11254535.html

2、https://blog.csdn.net/UbuntuTouch/article/details/102642703

3、https://elasticsearch.cn/article/13533




 
