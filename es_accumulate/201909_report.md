# 1、Elasticsearch 聚合不准确

回复：
1.聚合本来就是不精确的。

看一下官方解读：

As described above, the document counts (and the results of any sub aggregations) in the terms aggregation are not always accurate. 
https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html
 
2.如何更精确的实践方法：

方案1：设置主分片为1。注意7.x版本已经默认为1。 

适用场景：数据量小的场景。 
 
方案2：设置shard_size为比较大的值，官方推荐：size*1.5+10 

适用：数据量大的场景。 
 
方案3：早期版本中，我曾经将size设置为2的32次方减去1也就是分片支持的最大值，来解决精度问题。
 
原因：1.x版本，size等于0代表全部，高版本取消0值，所以设置了最大值。 
适用场景：不推荐使用了。

# 2、logstash gork 匹配自动换行日志

评价：实际业务可能会用到：https://elasticsearch.cn/question/8237

已经解决了，使用multiline，将每行日志都进行合并,在进行匹配
```
input {
file {
path => "/tomcat-/logs/cat-log/log_total.log"
type => "tomcat"
start_position => "beginning"
codec => multiline { #使用multiline插件，整合日志
pattern => "(.*请求URL.*) | (.*请求IP*.) | (.*请求方法*.) | (.*请求参数*.) | (.*接口耗时*.) | (.*返回参数*.) | (.*ERROR*.) | (.*-$)"
negate => true
what => "previous" #如果无法匹配，为上一行
}
}
}
```

# 3、面试题：elasticsearch 一个数字如何设置mapping，为什么？

考察对lucene底层数据存储结构的了解程度，看看吴大叔的文章吧https://elasticsearch.cn/article/446

铭毅观察：
考察点1：根据业务场景斟酌精度问题，没必要都是long或者高精度的double。
考察点2：实际业务场景是不是检索，可以考虑：keyword类型。

# 4、idea源码调试的问题
https://elasticsearch.cn/question/8243

回复：
我的环境是jdk12, idea2019.2 mac elasticsearch6.7。 比较奇怪的是启动后IDE并没有帮我打印出来启动参数，挺费解的。
我是后来自己写了一个主函数执行，发现xmx后面的单位用大写貌似有问题读不到。。。尴尬。

其实最麻烦的是后来找不到类的那个问题，这个问题我解决了两天。。 
包括你用的这个方法 Edit Configurations ，给 Include dependencies with Provided scope 打上勾 我也试了，没有效果。后来特地查了下这个东西的作用，结合gradle的打包配置尝试修改了下plugin那个模块的生命周期发现有效。

# 5、【推荐】一键部署高可用 Elasticsearch 集群

https://elasticsearch.cn/question/8258

分享一套简化 es 集群部署的工具，支持多种模式部署（测试集群模式、线上集群模式、多机房模式等），可快速部署生产级别可用的集群。
 
一个命令就可以完成全部部署工作，并支持多套集群混合部署，提高机器利用率。

项目采用 ansible 开发，不需要在服务器上预先安装客户端，只需要有 ssh 连接权限即可。

已在大厂经过长时期验证。欢迎大家使用。

项目地址：https://github.com/bluecll/es-easy-setup

# 6、Logstash设置queue.type为persisted

描述：如下面的代码，我部署的是最简单的es+logstash+kibana模式，在logatash的pipelines.yml中，设置了管道的属性，指定持久化以启用持久性队列，我发现logtash在/data下自动创建了该管道的文件夹。
 
 - pipeline.id: test
   pipeline.workers: 8
   path.config: "./config/ltest.conf"
   queue.type: persisted

 
问题1：那么logstash是会在当前文件夹中，另外存储一份日志数据吗？

回复：当前文件夹会暂存当前正在处理的数据，当成队列使用，即input已经取到该数据，而filter和output还没处理的数据。

问题2：如果logstash传输到es前，另外存储了一份数据，它会在传输给es后自动删除吗？
回复：会自动删除。

# 7、Elasticsearch 线程池问题

ES版本： 6.7.2
 
最近在看ES 的thread_pool的配置，然后这里有两种thread_pool感觉有点不清楚：
Write：For single-document index/delete/update and bulk requests.
index：For index/delete operations.
我感觉这两个线程池是不是有重合的地方，还是我理解的不对。然后我在网上找了区别：

In 6.x the WRITE threadpool is used for shard-level bulk and resync replication operations. The INDEX threadpool is used for other update, delete, and indexing operations.

上面的解答和我的理解有点不一样，所以请教一下各位。

回复：
write 在6.3版本之前叫bulk，主要就是处理bulk 和 resync 请求，也就是批量处理
 
index 是处理 单文档的 增删改  
 
7.0的时候把index去掉了，因为这个版本以后单文档的请求也通过bulk执行

# 8、springdata中ElasticsearchTemplate的startScroll是不是不支持高亮？

scroll确认可以的。
```
POST /message_infos-08/_search?scroll=1m
{
    "size": 100,
    "query": {
        "match" : {
            "content": "北京"
        }
    },
     "highlight": {
        "fields": {
            "content": {}
        }
    }
}
```

# 9、如何删除_id名称为%{id}的文件

铭毅备注：经常出现在实际开发中。
解决方案:
url encoding编码一下就可以了。
curl -XDELETE http://localhost:9200/test111/ ... retty
 
 
实测有效：
```
curl -XDELETE http://localhost:9200/test111/ ... retty
{
  "_index" : "test111",
  "_type" : "doc",
  "_id" : "${id}",
  "_version" : 4,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 3,
  "_primary_term" : 1
}
[size=13]
[/size]
```

# 10、求ELK6.X 开源告警方案

1、go-elasticalert
https://github.com/morningconsult/go-elasticsearch-alerts
 
2、elasticAlert
https://github.com/Yelp/elastalert
 
3、sentinl
https://github.com/sirensolutions/sentinl
实测：可以对接邮件ok。

# 11、elasticsearch怎么把两个字段放在一个桶里聚合去重？太难了...

考虑下对数据的预处理，
比如1：借助：copy_to 字段：https://www.elastic.co/guide/en/elasticsearch/reference/current/copy-to.html
比如2：借助：ingest 字段整合
 
去重的话借助：
1、cardinality
2、top_hits聚合
3、collapse折叠
 
https://blog.csdn.net/laoyang360/article/details/79905676

# 12、ES 7.X 版是如何防止腦裂發生
不好意思，請問ES 從 7 開始移除了minimum_master_nodes 參數，移除後是如何防止腦裂的狀況發生，我看了蠻多文章，不知道有沒有比較簡單的說明好理解，感謝!

新的 zen2 自动处理了，会根据当前集群的情况，自动调整所需的最小 master 节点数。

# 13、多条件多维度查询

有个业务场景，关系数据库中涉及的表有7个左右（表结构互不相同），平均每个表的数据量在500W左右，通过ES对这7个表数据做多条件、多维度的组合查询,包含聚合后按照数量查询（聚合目前是在应用程序中计算后写入ES）。该场景下在ES创建中对这7张表创建了nested结构的索引来实现需求，但发现该模式下扩展性太难，后续要加入新的表作为组合条件，很难实现。问下各位大神，有没有更好的方案支持该场景下的查询，要求查询响应快、扩展性高。谢谢

铭毅评论：实际中问的最多的问题之一，不要用关系型数据库的数据思维去使用Elasticsearch！

个人的理解:ES很多性能很强，用到关联关系的表需要慎重；严重影响到性能;一般多表查询的处理策略有4中：

1.建多个库，手工代码做关联；

优点：各表相互独立，扩展容易；

缺点：业务逻辑都需要自己处理，关联层数多，数据量大的搜索不适合。

2.宽表,合并所有的字段;

优点:关联关系搜索方便，而且数据量大不影响；

缺点：极不容易扩展，删除和更新复杂，很难维护；单文档容量大，有效字段比率少，影响IO性能；

3.父子文档：有层次关联的做父子文档;

优点:可以做层次关系的关联，而且不用关联的时候相互独立，增加修改删除方便；

缺点：关联关系也是昂贵的开销，影响性能；

场景：能够用于增删频繁的，查询少的业务；

4.nested嵌套，相当于一个java中字段为list对象，

优点:查询性能好，没有很大关联关系的开销；

缺点：单文档大，增加修改删除，很频繁不合适；

场景：适合用于很少对表做修改的业务；
 
ES多表查询，
第一：需要分析业务: 表的关联关系,每个表的增删状况，查询的的复杂程度，每个表的数据量级；
第二：多表方案选项,跟1的业务息息相关； es都能做，但是都不强，需要自己挑一个最合适的；
第三：后期维护方案：数据量的扩展，数据增删；能达到一个什么量级，这也关系到多表的选型方案；
 
一般上面,宽表和单表，大多数业务不适合，不建议使用；父子文档和嵌套，选型区别是：1. 修改频繁用父子文档，不频繁的用嵌套；2. 经常需要关联查询，优选嵌套；偶尔用一下关联用父子文档；

推荐：https://blog.csdn.net/laoyang360/article/details/88784748

# 14、生产环境的ELK版本如何升级

视频推荐：https://www.elastic.co/cn/webinars/upgrading-your-elastic-stack

# 15、有没有办法在 logstash 中删除 nested 中符合条件的 object？

https://elasticsearch.cn/question/8398

已解決
``` 
    ruby {
        code => '
            a = event.get("inventory_item")
            a = a.delete_if { |x| ! x["item_equipped"] }
            event.set("inventory_item", a)
        '
    }
```

# 16、大量数据写入Maybe ES overloaded？

【问题描述】

S的版本为：5.4
当前运行场景是这样的：
现在有6张hive表，数据量大小，规模均不一致。数据条数最多的有两千多万条，数据量少的有200w左右，多数表在500w条数据。表中最多的数据有大约200个字段。我处理的时候是对于每一张表，使用sparksql查到需要写入ES的数据，然后简单筛选一下。转换读取的json字符串为es能写的key-value形式。调用rdd写es的函数finalRdd.saveToEsWithMeta(resource, esConfig)将结果写入。
我的es配置大概如下（对应于es配置es.batch.size，在scala代码中做了配置文件的映射es_batch_size对应于es.bastch.size）：
es_batch_size=1200
es_batch_refresh=false
es_batch_retry_count=10
es_batch_retry_wait_second=30
es_write_operation=upsert
写入的时候提示的错误几乎全是上面Maybe ES was overloaded?我做了如下尝试：
1.每个rdd写入es的时候数据量太大，超过了es的最大写入量（我的猜想）RDD处理的时候有一个repartition操作，可以将大量的RDD数据分散存放在不同的机器上，我尝试修改这个值让他更大，保证分到机器上RDD更小，对RDD再调用saveToEsWithMeta写入数据（50-150）。还是提示这样的错误。
2.es_batch_size比较小，每次处理的时候需要频繁的拿数据比较耗时（我的猜想），调高es_batch_size(最高设置到3000)。也是时常出现这样的错误。
3.因为偶然的因素比如集群资源波动导致es数据写入失败（我的猜想），于是我尝试添加更多的es_batch_retry_count,最多设置过60,效果依然不明显。es_batch_retry_wait_second这个时间我也修改过(改大，我猜想ES写宽表的时候可能辉比较慢，这时候当处理到宽表的时候，批处理容易超时，改大可能会好一点（最大改到了60）)，效果依旧不明显。问题还是时有发生。
现在不知道还有什么方法可以尝试，想问一下大家有没有碰到类似的问题，通常是如何解决的，不同规模的数据在往es写的时候同样ES配置是同样的吗？还有上面queued tasks = 216意思是不是我的es队列大小为200,队列中等待的任务超过了200,请求写入es的操作被拒绝了。是这样吗？

回复：
es序列化具体设置:es.batch.size.bytes (default 1mb)
es.batch.size.entries (default 1000)
你的字段比较多，单个doc文档比较大，es.batch.size.entries可适当调小，es.batch.size.bytes 可以大一点；
这个你可以自己根据硬盘性能和分片数自己设置;
例如:硬盘读写60M/s，集群12台，24个分片，2个副本，平均一台集群上有2个主分片需要写入，4个副本分片需要同步；那么每秒写入的理论上是60*12/3= 240M/s; 所以，可以适当调整es.batch.size.bytes；然后计算你单个doc的字节数；es.batch.size.bytes除以单个doc，就可以预估一个es.batch.size.entries的值；

# 17、es集群起步三台，什么情况下用5台或者7台？？？

doom同学的回答很干脆。

https://elasticsearch.cn/question/8413

这个没什么只指标吧；大多数是根据分片和内存来的；
1：30GB堆内存的节点最多可以有600-750个分片；单分片的记录条数不要超过上限2,147,483,519；一个分片30G，单台最大库容量，17.5T到22T；
2：读性能考虑;副本分片的数量；不单单是读取硬盘数据，还有计算性能，性能不足时需要添加几台
3：写性能考虑:主分片数量；
综合上面的；2和3，直接关系到分片的个数；关系也是密切的；集群规划，是根据这些考虑的；需要是总分片数。

# 18、es查询结果超过16位导致精度丢失

wood大叔：我在ES英文论坛问过这个问题
https://discuss.elastic.co/t/long-json-number-lost-precision/72124/12 ，结论是javascript本身的限制导致ES的Dev Console显示的数值丢失精度，如果在命令行下用curl去查询就不会有问题。 

# 19、【推荐】集群规划官方文档翻译
问题讨论：https://elasticsearch.cn/question/8429

https://blog.csdn.net/xuguokun1986/article/details/91861796

# 20、Logstash服务启动为什么会把Elasticsearch服务杀死

问题探究：这不是logstash能把ES搞死，实际场景：mysql或者你的后台程序都有可能。
logstash非常耗费内存，建议：单机部署。
ES多数据量业务场景，建议：单机独立部署。

# 21、logstash消费kafka数据乱码

https://elasticsearch.cn/question/8442

【回复】
1. 数据源是gbk，input 里面解析为“GBK ，可以正常输出，默认是utf-8；output里面不用添加 charset=>"GBK"；
2.检查你的系统默认字符集；echo $LANG ;确保utf-8；
3.控制台的输出环境，也设置为utf-8；
 
以上3点做到，就可以正常显示；


# 22、kibana7.2 用api创建index pattern如何指定space？

【问题描述】
方给出了如下的通过cURL调用kibana api的方法，但只能在default空间创建index pattern。
如果要指定space的话需要添加什么呢？
```
curl -k -u username:passwd -X POST "localhost:5601/api/saved_objects/index-pattern/my-pattern" -H 'kbn-xsrf: true' -H 'Content-Type: application/json' -d'
{
  "attributes": {
    "title": "my-pattern-*"
  }
}
'
```

medcl回复：
```
POST /s/<space_id>/api/saved_objects/index-pattern/my-pattern
{
  "attributes": {
    "title": "my-pattern-*"
  }
}
```


# 23、推荐：Elasticsearch: analyzer 教程
https://blog.csdn.net/UbuntuTouch/article/details/100392478

铭毅天下
20191007 22:51
